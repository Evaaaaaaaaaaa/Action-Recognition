{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data into dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import os\n",
    "import numpy as np\n",
    "path = 'groundTruthmat/'\n",
    "dataset = []\n",
    "files = os.listdir(path)\n",
    "data_dict = {}\n",
    "# devide four folds\n",
    "# s1: P03 – P15\n",
    "# s2: P16 – P28\n",
    "# s3: P29 – P41\n",
    "# s4: P42 – P54\n",
    "for file in files:\n",
    "    read = scipy.io.loadmat(path + file)\n",
    "    data_dict[file] = read['labseqid']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot():\n",
    "# create frame_label for one hot encoding\n",
    "    frame_label = {}\n",
    "    for i in range(48):\n",
    "        frame_label[i] = 48*[0]\n",
    "        frame_label[i][i] = 1\n",
    "    frame_label[-1] = 48*[0]\n",
    "    return frame_label\n",
    "\n",
    "frame_label = one_hot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_frames(data_dict, trainProportion):\n",
    "    new_dict = {}\n",
    "    train_y = []\n",
    "    for filename, frames in data_dict.items():\n",
    "        frameLen = len(frames)\n",
    "        \n",
    "        inputLen = round(frameLen*trainProportion)  \n",
    "        inputFrames = frames[:inputLen]\n",
    "        new_dict[filename] = inputFrames\n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_y(data_dict, input_dict):\n",
    "    train_y = []\n",
    "    for filename, frames in data_dict.items():\n",
    "        frame_len = len(input_dict[filename])\n",
    "#         print(input_dict[filename])\n",
    "        y = [input_dict[filename][frame_len-1][0]]\n",
    "        for frame in frames[frame_len:]:\n",
    "#             print(frame[0], y[-1])s\n",
    "            if frame[0] != y[-1]:\n",
    "                y.append(frame[0])\n",
    "        y.pop(0)\n",
    "\n",
    "        train_y.append(y)\n",
    "    return train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert seccessive frmaes of same action to single action\n",
    "\"\"\" data_dict structure eample\n",
    "    {'P25_stereo01_P25_sandwich.mat': array([[ 0],\n",
    "        [ 0],\n",
    "        [ 0],\n",
    "        ...,\n",
    "        [39],\n",
    "        [39],\n",
    "        [39]], dtype=int32),\"\"\"\n",
    "\n",
    "def frames_to_action(input_dict):\n",
    "    for filename, frames in input_dict.items():\n",
    "        action_list = []\n",
    "        for frame in frames:\n",
    "            if len(action_list) == 0:\n",
    "                action_list.append(frame[0])\n",
    "            else:\n",
    "                if frame[0] != action_list[-1]:\n",
    "                    action_list.append(frame[0])\n",
    "        input_dict[filename] = action_list   \n",
    "    return input_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add padding, each video has same length of action input\n",
    "def add_padding(data_dict):\n",
    "    maxLen = 0\n",
    "    count = 0\n",
    "    for frames in data_dict.values():\n",
    "        if len(frames) > maxLen:\n",
    "            maxLen = len(frames)\n",
    "    for filename, frames in data_dict.items():\n",
    "#         print(frames)\n",
    "        data_dict[filename] = (maxLen - len(frames)) * [-1]  + frames\n",
    "    return data_dict, maxLen\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_padding_to_y(trainY):\n",
    "    maxLen = 0\n",
    "    count = 0\n",
    "    new_trainY = []\n",
    "    for frames in trainY:\n",
    "        if len(frames) > maxLen:\n",
    "            maxLen = len(frames)\n",
    "    for frames in trainY:\n",
    "        \n",
    "        temp = (maxLen - len(frames)) * [-1] +frames\n",
    "        new_trainY.append(temp)\n",
    "    return new_trainY, maxLen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_encoding(input_dict):\n",
    "    for filename, frames in input_dict.items():\n",
    "        # get corresponding one-hot encode\n",
    "        new = []\n",
    "        for each in frames:\n",
    "            new.append(frame_label[each])\n",
    "        input_dict[filename] = new\n",
    "    return input_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def label_encoding(trainY):\n",
    "    new_trainY = []\n",
    "    for frames in trainY:\n",
    "        new = []\n",
    "        for each in frames:\n",
    "            new.append(frame_label[each])\n",
    "        new_trainY.append(new)\n",
    "    return new_trainY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, RepeatVector\n",
    "from keras.layers import Dropout, Masking, TimeDistributed, Activation\n",
    "def lstm_model(frame_len, max_timesteps):\n",
    "    model = Sequential()\n",
    "    # Change to input layer\n",
    "    model.add(Masking(mask_value = 48*[0], input_shape=(frame_len,48)))\n",
    "    model.add(LSTM(512, activation='tanh', return_sequences=True)) \n",
    "    model.add(LSTM(256))\n",
    "    model.add(RepeatVector(max_timesteps))\n",
    "    model.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(48, activation = \"softmax\")))\n",
    "    model.compile(loss='mae', optimizer='adam', metrics=['accuracy'], sample_weight_mode=\"temporal\")\n",
    "    model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "def train_model(trainX, trainY, model):\n",
    "    model.fit(np.array(trainX), np.array(trainY), epochs = 20, batch_size = 128)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evaluation(testX, testY, model, max_timesteps):\n",
    "    predictions = model.predict(testX)\n",
    "#     print(predictions)\n",
    "    results = []\n",
    "    count = 0\n",
    "    accuracy_list = []\n",
    "    for i in range(len(predictions)):\n",
    "        each_video = []\n",
    "        for j in range(len(predictions[i])):\n",
    "            result = np.array([0] * 48)\n",
    "            index = predictions[i][j].argmax(axis=-1)\n",
    "            result[index] = 1\n",
    "            each_video.append(result)\n",
    "        results.append(each_video)\n",
    "    \n",
    "    \n",
    "    # delete paddings\n",
    "    for i in range(len(testY)):\n",
    "        count = 0\n",
    "        for j in  range(len(testY[i])):\n",
    "            if (testY[i][j] == 48*[0]).all():\n",
    "                count += 1\n",
    "        testY[i] = testY[i][count:]\n",
    "        results[i] = results[i][count:]\n",
    "\n",
    "    \n",
    "    # max number of actions in the output\n",
    "    for i in range(max_timesteps):\n",
    "        correct = 0\n",
    "        valid = 0\n",
    "        # loop each video\n",
    "        for j in range(len(testY)):\n",
    "            if len(testY[j]) > i:\n",
    "                if not (results[j][i] == 48*[0]).all():\n",
    "                    valid += 1\n",
    "\n",
    "                    if (testY[j][i] == results[j][i]).all():\n",
    "                        correct += 1\n",
    "        if valid == 0:\n",
    "            accuracy_list.append(0)\n",
    "            print(\"timestpe\", i+1, \":\",  0)\n",
    "        else:\n",
    "            accuracy_list.append(correct/valid)\n",
    "            print(\"timestpe\", i+1, \":\",  correct/valid)\n",
    "    return (accuracy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from operator import add\n",
    "def cross_validation(input_dict, encoded_y, model, max_timesteps):\n",
    "    file_count = 0\n",
    "    s1_x, s2_x, s3_x, s4_x = [], [], [], []\n",
    "    s1_y, s2_y, s3_y, s4_y = [], [], [], []\n",
    "    # s1: P03 – P15\n",
    "    # s2: P16 – P28\n",
    "    # s3: P29 – P41\n",
    "    # s4: P42 – P54\n",
    "    count = 0\n",
    "    for filename, frames in input_dict.items():\n",
    "        if int(filename[1:3]) <= 15:\n",
    "            s1_x.append(input_dict[filename])\n",
    "            s1_y.append(encoded_y[file_count])\n",
    "        elif 16 <= int(filename[1:3]) <= 28:\n",
    "            s2_x.append(input_dict[filename])\n",
    "            s2_y.append(encoded_y[file_count])\n",
    "        elif 29 <= int(filename[1:3]) <= 41:\n",
    "            s3_x.append(input_dict[filename])\n",
    "            s3_y.append(encoded_y[file_count])\n",
    "        elif 42 <= int(filename[1:3]) <= 54:\n",
    "            s4_x.append(input_dict[filename])\n",
    "            s4_y.append(encoded_y[file_count])\n",
    "        file_count += 1\n",
    "        \n",
    "    splits_x = [s1_x, s2_x, s3_x, s4_x]\n",
    "    splits_y = [s1_y, s2_y, s3_y, s4_y]\n",
    "    final_acc = []\n",
    "    for i in range(4):\n",
    "        trainX = None\n",
    "        trainY = None\n",
    "        for j in range(4):\n",
    "            if splits_x[j] != splits_x[i]:\n",
    "                if trainX == None:\n",
    "                    trainX = copy.deepcopy(splits_x[j])\n",
    "                else:\n",
    "                    trainX += copy.deepcopy(splits_x[j])\n",
    "\n",
    "            if splits_y[j] != splits_y[i]:\n",
    "                if trainY == None:\n",
    "                    print(np.array(splits_y[j]).shape)\n",
    "                    trainY = copy.deepcopy(splits_y[j])\n",
    "                else:\n",
    "                    trainY += copy.deepcopy(splits_y[j])\n",
    "        testX = copy.deepcopy(splits_x[i])\n",
    "        testY = copy.deepcopy(splits_y[i])\n",
    "#         print(np.array(trainX).shape, np.array(trainY).shape,)\n",
    "        train_model(trainX, trainY, model)\n",
    "        if final_acc == []:\n",
    "            final_acc =  evaluation(testX, testY, model, max_timesteps)\n",
    "            \n",
    "        else:\n",
    "            final_acc = list( map(add, final_acc,  evaluation(testX, testY, model, max_timesteps)) )\n",
    "#         print(final_acc)\n",
    "    final_acc = [i/4 for i in final_acc]\n",
    "    print(final_acc) \n",
    "    return (final_acc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_2 (Masking)          (None, 6, 48)             0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 6, 512)            1148928   \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 256)               787456    \n",
      "_________________________________________________________________\n",
      "repeat_vector_2 (RepeatVecto (None, 23, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 23, 100)           142800    \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 23, 48)            4848      \n",
      "=================================================================\n",
      "Total params: 2,084,032\n",
      "Trainable params: 2,084,032\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(451, 23, 48)\n",
      "Epoch 1/20\n",
      "12/12 [==============================] - 1s 101ms/step - loss: 0.0249 - accuracy: 0.7355\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 1s 100ms/step - loss: 0.0249 - accuracy: 0.8376\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 1s 97ms/step - loss: 0.0249 - accuracy: 0.8376\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 1s 99ms/step - loss: 0.0249 - accuracy: 0.8376\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 1s 102ms/step - loss: 0.0248 - accuracy: 0.8376\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 1s 102ms/step - loss: 0.0234 - accuracy: 0.8376\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 1s 104ms/step - loss: 0.0234 - accuracy: 0.8376\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 1s 100ms/step - loss: 0.0234 - accuracy: 0.8376\n",
      "Epoch 9/20\n",
      " 2/12 [====>.........................] - ETA: 0s - loss: 0.0233 - accuracy: 0.8421"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-e8d2d7b168e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mencoded_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_timesteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_timesteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;31m#     results[proportion] = result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#     clear_session()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-494491986de9>\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(input_dict, encoded_y, model, max_timesteps)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mtestY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplits_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m#         print(np.array(trainX).shape, np.array(trainY).shape,)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfinal_acc\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mfinal_acc\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mevaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_timesteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-a3313f473066>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(trainX, trainY, model)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.backend import clear_session\n",
    "# input_proportion = [0.1]\n",
    "input_proportion = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "results = {}\n",
    "for proportion in input_proportion:\n",
    "    input_dict = get_input_frames(data_dict, proportion)\n",
    "    train_y = get_input_y(data_dict, input_dict)\n",
    "    input_dict = frames_to_action(input_dict)\n",
    "    input_dict, frame_len = add_padding(input_dict)\n",
    "    input_dict = feature_encoding(input_dict)\n",
    "    \n",
    "    train_y, max_timesteps = add_padding_to_y(train_y)\n",
    "    encoded_y = label_encoding(train_y)\n",
    "    encoded_y = np.array(encoded_y)\n",
    "    model = lstm_model(frame_len, max_timesteps)\n",
    "    result = cross_validation(input_dict, encoded_y, model, max_timesteps)\n",
    "#     results[proportion] = result\n",
    "#     clear_session() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
